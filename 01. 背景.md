## Chapter 1      Background //背景

### 關於本章

為了建立理解PCI Express（PCIe）架構的基礎，本章首先回顧了早於PCIe總線出現的PCI（Peripheral Component Interface外設組件接口）總線模型，並介紹了PCI和PCI-X (PCI‐eXtended) 的基本特徵以及各自的特點。接著討論了從早期的並行總線模型遷移到PCIe使用的串行高速總線模型的出發點和動機。

### 關於下一章

下一章對PCIe體系結構進行了介紹，並打算作一個“操作執行級（executive level）”的概述，它涵蓋了高層體系結構的所有基礎內容。這部分介紹了協議規範中給出的分層的PCIe端口設計方法，並描述了每個層級的職責作用。

### 1.1 引言

想要理解PCIe的第一步，是要對PCIe所基於的先前技術建立堅實的基礎，而本章則將對它們的體系結構進行概述。已經對PCI比較熟悉的讀者可以跳過本章去看下一章。如本章標題「背景」，本章僅意在給出一個簡明的概述。對於關於PCI和PCI-X的更深更細節的內容，請參考MindShare的書籍《PCI System Architecture》以及《PCI-X System Architecture》。

這裡可以通過舉一個例子來說明為什麼本章的背景介紹對理解PCIe是有幫助的，現在在PCIe上使用的軟體（驅動）與當初在PCI上使用的軟體大致相同。保持這種向後的相容性，使得舊的設計遷移到新的設計（PCI到PCIe）時可以讓軟體的修改儘可能少、花費儘可能低的成本，這即是在鼓勵舊設計向新設計遷移。最終的結果就是，舊的支持PCI的軟體在PCIe系統中的工作方式無需發生改變，而新的軟體（PCIe的驅動軟體）也將按照PCI一樣的模型進行操作（例如對配置空間的操作）。基於這樣的原因以及其他的一些原因，理解PCI以及它的操作模型將有助於促進對PCIe的理解。

### 1.2 PCI與PCI-X

PCI（Peripheral Component Interface外設組件介面）總線於1990年代初被開發出來，當時人們期望用它來解決PCs（personal computer個人電腦）的外設總線的一些缺點。那個年代的技術標準是IBM的AT總線（Advanced Technology），它也被其他供應商稱為ISA總線（Industry Standard Architecture）。ISA總線是為286 16位計算機而設計的，在286上也發揮了足夠的性能，但隨著新型的32位計算機及其外設們出現，新的需求也出現了：更高的帶寬、更多更好的功能（例如即插即用）。此外，ISA總線使用的連接器是具有較多針腳數的大型連接器。PC供應商們認識到了需要做出一定的改變，幾種用於替代ISA總線的設計也被提出，例如IBM的MCA（Micro-Channel Architecture），EISA總線（Extended ISA，這是由IBM的競爭對手提出的），以及VESA總線（Video Electronics Standards Association，它由聲卡供應商們為適配聲卡而提出）。然而，所有的這些設計都具有一些使得它們無法被普及的缺點。最終，一個由PC市場的主要公司們共同聯合建立的組織PCISIG（PCI Special Interest Group）開發出了PCI總線，並將其作為一種開放總線。在當時，PCI這種新型總線體系結構在性能上大大地優於ISA，而且它在每個裝置內部新定義了一組寄存器，稱之為配置空間（configuration space）。這些寄存器使得軟體可以查看一個PCI裝置內部所需的存儲和IO資源，同時讓軟體為一個系統下的各個裝置分配互不衝突的地址。這些特性：開放式設計、高速、軟體可見性與可控性（software visibility and control），幫助PCI克服了限制ISA與其他總線的發展障礙，讓PCI迅速地成為了PC中的標準外設總線。

幾年之後，PCI-X（PCI eXtended）被開發出來，作為PCI體系結構的一種邏輯擴展（logical extension），並將總線性能提升了不少。我們將稍後再討論PCI-X相較於PCI的改變，但需提前一提的是PCI-X的一個主要設計目標就是保持與PCI裝置的可相容性，而且是軟體和硬體的相容性都要保證，這將使得從PCI遷移至PCI-X盡可能的簡單。不久後，PCI-X 2.0版本將速率提升到了更高，原始數據速率達到了4GB/s。因為PCI-X保持了對PCI硬體上的向後相容性，所以它依然是一個並行總線，並繼承了與該總線模型相關的一些問題。有趣的事情來了，並行總線的有效帶寬最終會達到一個實際的上限（practical ceiling），然後就無法簡單地繼續提升。而PCISIG一直在探索如何將PCI-X的速率進一步提升，但最終這項努力還是被放棄了。這種速率上限，連同多針腳的連接方式，雖然是並行總線的缺點但是同時也提供了動力，推動了並行總線模型向新型的串行總線模型轉型。

這些早期總線的定義被羅列在表 1‑1，它展示了隨時間發展而變得更高的帶寬與頻率。表中有一點很有趣的地方，那就是時鐘頻率和總線上插板卡的插槽数量之間的相關性。這是由PCI的低功耗信號模型帶來的，這意味著更高的總線頻率需要更短的板上走線以及更少的總線負載（詳情可見“Reflected-Wave Signaling”）。另外有趣的一點是，隨著總線頻率的增加，共享總線上允許的裝置數量在減少。當PCI-X 2.0被引入使用時，想要達到它的高速率需要要求總線變為一個點對點的互連（point-to-point interconnect）。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image002.jpg)

表 1-1 匯流排頻率、頻寬、插槽數量的對比

### 1.3 PCI基礎(PCI Basics)

#### 1.3.1 基於PCI的系統的一些基礎知識

圖 1-1 展示了一個基於 PCI 匯流排的老系統架構。該系統包括一個北橋（North Bridge，之所以稱為“北”，是因為如果將圖看作一張地圖，它位於中央 PCI 匯流排的北方向），北橋是處理器與 PCI 匯流排之間的介面。與北橋相連的是處理器匯流排（processor bus）、系統記憶體匯流排（system memory bus）、AGP 圖形匯流排（AGP graphics bus），以及 PCI 匯流排。幾個裝置將會共用 PCI 匯流排，它們要麼直接與匯流排相連，要麼作為插入板卡插入到連接器上。在中央 PCI 匯流排的“南方”有一個南橋（South Bridge），它用於將 PCI 與系統外設相連接，這裡的系統外設可以是為了使用舊的遺留裝置而應用發展了多年的 ISA 匯流排。南橋通常也是 PCI 的中心資源區（central resource），它提供了一些系統訊號如復位、參考時鐘和錯誤報告操作。

![image-20211222230411470](img/1%20%E8%83%8C%E6%99%AF/image-20211222230411470.png)

圖 1‑1 基於舊PCI匯流排的平台

#### 1.3.2 PCI匯流排發起方(Initiator)與目標方(Target)

在PCI層級結構中，匯流排上的每個裝置（device）可以包含最多8個功能（function），這些功能都共享該裝置的匯流排介面，功能編號為0到7（一個僅具有單功能的裝置通常將被分配功能號0）。每個功能都能作為匯流排上事務傳輸（transaction）的目標方，而且它們中的大多數還可以作為事務傳輸的發起方。這樣的發起方（稱為匯流排主裝置）有一對針腳（REQ#與GNT#，符號#表示它們為低有效訊號），這一對訊號用來處理共享PCI匯流排時的仲裁。如圖 1‑2所示，請求訊號（REQ#）有效時表示主裝置需要使用匯流排，並將此信息告知匯流排仲裁器來與此時所有的其他請求一起進行評估仲裁，最終將得出下一時刻由哪一個裝置來占用PCI匯流排。仲裁器通常位於橋（bridge）中，橋是一種在層級結構中位於匯流排之上的結構，它可以接收匯流排上所有事務傳輸發起方（匯流排主裝置）所發出的仲裁請求。仲裁器將決定誰下一個占用匯流排，並將這個裝置的Grant（GNT#）置為有效（asserts the Grant pin for that device）。根據協議，只要匯流排上的上一個事務傳輸結束且匯流排進入空閒狀態時，對於任意裝置，只要在此時看到自己的GNT#訊號被置為有效，那麼就可以認為它是下一個占用匯流排的主裝置，它就可以開始發起它的事務傳輸。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image006.jpg)

图 1‑2 PCI总线仲裁

#### 1.3.3     典型的PCI总线周期

圖 1‑3 展示了一次典型的PCI匯流排週期。PCI匯流排是同步匯流排，這意味著匯流排上的活動都發生在時鐘邊緣，因此將時鐘訊號放在圖標的頂部，並將它的上升沿都用虛線標註出來，這是因為訊號正是在這些虛線所表示的時刻被發出（driven out）或被採樣（sampled）。下面對匯流排上發生了什麼進行一個簡明的描述。

1. 在時鐘沿1，FRAME#訊號（此訊號有效時表示正在進行匯流排訪問）和IRDY#訊號（Initiator ReaDY for data，發起方準備好數據）這兩個訊號都處於無效狀態，這表示匯流排處於空閒狀態。與此同時，GNT#有效，這意味著匯流排仲裁器已經選擇了該裝置作為下一個事務傳輸發起方（Initiator）。

2. 在時鐘沿2，發起方將會把FRAME#訊號置為有效，這表示一個新的事務傳輸已經被它發起。與此同時，它將把這個事務的地址與命令驅動到匯流排上。匯流排上其他所有的裝置都將會把這些信息鎖存起來，並將地址譯碼，查看自己的地址是否與之相匹配。

3. 在時鐘沿3，發起方將IRDY#訊號置為有效，這表示它已經準備好了進行數據傳輸。圖中AD匯流排上的環形箭頭符號表示這個三態匯流排（可以理解為inout型）正處於「轉向週期」，這意味著這個訊號的擁有者（三態匯流排上的訊號此時是誰驅動的）發生了變化（這裡出現「轉向週期turn-around cycles」是因為這是一個讀事務；發起者發出地址信息和接收數據的訊號引腳是相同的）。打開目標方（Target）的緩衝buffer的時鐘沿與關閉發起方緩衝buffer的時鐘沿不能相同，因為我們想儘量避免兩個 buffer 都在驅動同一個訊號的可能性（即都往AD匯流排上驅動數據），哪怕只是很短的時間也不行。匯流排的爭用將會損壞裝置，因此，需要在前一個buffer關閉後的下一個時鐘再打開一個新的 buffer。在改變匯流排的驅動方向之前，每個共享訊號都需要這樣進行處理。

4. 在時鐘沿4，匯流排上的一個裝置識別到了請求的地址與自己相匹配，於是便通過將DEVSEL#訊號（device select）置為有效的方式對事務發出響應，宣告參與到事務中。與此同時，它將把 TRDY# 訊號（Target ReaDY）置為有效，這表示它（Target）正在發送讀數據的第一部分，並將數據驅動到AD匯流排上（放到匯流排上的時間可以後延，匯流排允許目標方在FRAME#有效與TRDY#有效間間隔最多16個時鐘週期）。由於此時 IRDY# 與 TRDY# 都處於有效狀態了，數據將在此上升沿開始傳輸，至此完成了第一個數據階段（first data phase）。Initiator 知道最終一共要傳輸多少位元組的數據，但是 Target 並不知道。在事務的命令信息中並不包含位元組數信息，因此每當完成一個數據階段，Target 都必須查看 FRAME# 訊號的狀態，以此來得知 Initiator 是否對傳輸的數據量滿意（即是否達到 Initiator 需要的數據量）。如果FRAME#依然有效，那麼說明這並不是最後一個數據階段，Target 仍然需要繼續向 Initiator 傳輸數據，事務將按照相同的方式繼續處理接下來傳輸的位元組。

5. 在時鐘沿5，Target 還沒有準備好繼續發送下一組數據，因此它將 TRDY# 置為無效。我們將這種情況稱為插入了一個「等待狀態」，這使得事務被延遲了一個時鐘週期。Initiator和Target都可以進行這樣的操作，它們最多可以將下一次數據傳輸後延8個連續的時鐘週期。

6. 在時鐘沿6，第二組數據被傳輸，並且由於傳輸後FRAME# 訊號依然有效，Target就知道依然需要繼續向Initiator傳遞數據。

7. 在時鐘沿7，發起者(Initiator)強制匯流排進入了一個等待狀態。在等待狀態中，裝置可以使當前事務傳輸暫停，並快速地將要傳送的數據填充進緩衝區或是將接收到的緩存在緩衝區內的數據搬出，能進行這樣的操作是因為發起者和目標端(Target)允許事務在暫停後直接恢復，而不需要進行中止和重啟事務的操作。但是從另一方面來說，這樣的操作將會十分低效，因為它不僅使當前事務停頓，同時也禁止其他裝置訪問和使用匯流排，儘管此時匯流排上沒有數據在傳輸。

8. 在時鐘沿8，第三組數據被傳輸，並且此時FRAME#訊號被置為無效，因此目標端得知這就是最後一次數據傳輸。因此，在這一個時鐘週期後，所有的控制訊號線都關閉，匯流排再次進入了空閒狀態。

在PCI匯流排上，許多訊號都具有多種含義，這是為了減少引腳數量，以此來保持PCI設計中的低成本這一設計目標。數據和地址訊號一起複用32位匯流排，C/BE#（Command/Byte Enable）訊號也共享他們的4個訊號引腳。儘管減少引腳數量是一種可行的方法，並且它也是PCI使用“轉向週期”這種會增加延時的方法的原因。但是這種複用引腳的做法阻止了對事務傳輸的流水線操作（在傳送上一個週期的數據的同時傳送下一個週期的地址）。握手訊號諸如FRAME#、DEVSEL#、TRDY#、IRDY#以及STOP#被用來控制在事務進行期間，各事件何時進行。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image008.jpg)

图 1‑3简单的PCI总线传输

#### 1.3.4     反射波信号传输(Reflected-Wave Signaling)

PCI體系結構支持每條匯流排上最多掛載32個裝置，但是由於實際的電氣上限要小得多，在33MHz的基頻下大約可以支持10到12個電氣負載。出現這種現象是由於匯流排使用了一種技術稱為“反射波訊號傳輸”，該技術可以降低匯流排上的功率損耗（如圖 1‑4）。在這個模型中，裝置通過實現弱傳輸緩衝區（weak transmit buffer）來達到節省成本與功耗的目的，這種方法可以僅需一半的驅動電壓即可完成訊號電平的翻轉。訊號的入射波沿著傳輸線傳輸下去，直到到達傳輸線的末端。按照設計，傳輸線的末端沒有終結電阻（termination）吸收回波，所以訊號傳輸並沒有就此中止，波陣面（wavefront）在遭遇傳輸線末端的無窮大阻抗後會被反射回來。這種反射自然是具有疊加性的，當訊號返回發射方時，它會與入射訊號疊加使訊號增加到全電壓電平。當這樣的反射訊號到達初始的緩衝區時，緩衝區驅動器的低輸出阻抗會中止這個訊號的傳輸以及停止其繼續反射。因此，從緩衝區發出一個訊號一直到接收方檢測到有效的訊號所花費的時間，就等於訊號沿線路傳輸的時間加上反射回來的延遲時間和建立時間。所有這些都必須小於一個時鐘週期。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image010.jpg)

图 1‑4 PCI的反射波信号传输

當走線長度和匯流排上的電氣負載數量增加時，訊號往返所需要的時間也增加。一個33MHz的PCI匯流排只能滿足最多10-12個電氣負載的訊號時序要求。一個電氣負載指的是系統板上安裝的一個裝置，但是實際上一個插了板卡的連接器插槽被算作兩個電氣負載。因此，如表 1‑1所示的那樣，一個33MHz的PCI匯流排最多只能支持至多4個或者5個插入板卡型裝置，否則將無法保證可靠性。

為了在一個系統中接入更多的負載，需要使用PCI-to-PCI橋接器，如圖 1‑5所示。隨著越來越多更為先進的主晶片組的出現，外設的發展也十分迅速，以至於競爭訪問共享PCI匯流排成為了限制外設性能的原因。PCI匯流排的速率沒有跟上外設速率增長的腳步，雖然它依舊是主流的外設匯流排，但是已經成為了系統的性能瓶頸。這個問題的解決辦法為，把PCI移到系統外設與存儲器之間的主路徑之外，將晶片組互連用一些專有的解決方案來替代（例如Intel的Hub Link Interface）。

PCI橋接器是拓撲結構的延伸。每個橋接器都能產生新的PCI匯流排，而且這種由PCI橋接器產生的PCI匯流排與上層PCI匯流排在電氣上是相隔絕的，因此它也可以獨立地提供額外的10-12個電氣負載。PCI匯流排上的一些裝置也可以作為橋接器，可以令較多的裝置接入系統中。PCI體系結構允許在單系統中存在256條匯流排，每條匯流排下最多可以掛載32個裝置。

 

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image012.jpg)

圖 1‑5 包含 PCI-to-PCI bridge 的 33MHz PCI 系統

### 1.4 PCI 匯流排架構觀點 (PCI Bus Architecture Perspective)
#### 1.4.1 PCI 事務模型

PCI與先前的匯流排模型一樣，在數據傳輸上使用三種模型：可程式輸入輸出（Programmed I/O，簡稱PIO）、對等傳輸（Peer-to-peer）以及直接記憶體存取（Direct Memory Access，簡稱DMA）。這些模型的圖解如圖 1‑6所示，接下來的幾個小節將對它們進行描述。

##### 1.4.1.1 Programmed I/O(PIO)

可程式輸入輸出（PIO）在早期PC中被廣泛使用，因為設計者不願增加裝置中由於事務管理邏輯而帶來的成本開銷以及額外增加的複雜度。在當時，處理器比任何其他裝置工作的都要快，所以在這個模型中，處理器包辦了所有的工作。舉例來說，當一個PCI裝置向CPU發出中斷，並表示它需要向記憶體中放入數據，則由CPU最終將數據從PCI裝置中讀出並放入一個內部暫存器中，然後再將這個內部暫存器的值複製進記憶體中。反之，如果數據要從記憶體移動到PCI裝置中，那麼軟體會指示CPU將記憶體中的數據讀出至內部暫存器中，然後再將內部暫存器的值寫入到PCI裝置中去。

這樣的操作流程雖然可行，但是效率卻比較低，其主要有兩個原因。第一個原因，每一次數據傳輸都需要CPU開銷兩個匯流排週期。第二個原因，在數據傳輸過程中CPU都要忙於數據傳輸而不能做其他更有意義的任務。在早期，這是一種最快速的傳輸方式，而且單任務處理器也沒有其他的任務要做。然而這種低效的方式顯然不適用於更為先進的系統中，因此這種方式已不再是數據傳輸的常用方式，取而代之首選方法的是下一節將講述的DMA方法。然而為了使軟體與裝置交互，可程式輸入輸出仍然是一種必要的事務模型。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image014.jpg)

圖 1‑6 PCI事务模型

##### 1.4.1.2   Direct Memory Access(DMA)

在傳輸資料的方法上，一種更為高效的方式叫做 DMA（Direct Memory Access，直接記憶體存取）。在這個模型中有另一種裝置稱為DMA Engine，由它來代表處理器來負責掌握從記憶體向週邊設備進行資料傳輸的各種細節操作，這就將CPU從這個繁瑣的任務中解放出來。一旦CPU將起始地址（starting address）和資料位元組總量（byte count）寫入DMA Engine，DMA Engine將會自動處理匯流排協議與地址序列。這不涉及 PCI 週邊設備的任何更改，並允許其自身保持低成本設計。後來，經過集成性改進，週邊設備自身可以集成入這種DMA功能，這樣它們就不再需要一個外部的DMA Engine。這些裝置有能力處理自己發起的匯流排傳輸，我們將它們稱為匯流排主裝置（Bus Master device）。

圖 1‑3 就是一個PCI匯流排上的匯流排主裝置正在進行事務的過程。北橋可以對地址進行解碼，以此來識別自己是否是這個事務的Target，比如北橋解碼後發現地址與自己相匹配則認為自己是這個事務的Target。在匯流排週期中的資料傳輸階段，資料在匯流排主裝置與北橋之間傳輸，北橋即是資料傳輸的Target。北橋繼而根據請求的事務內容，發起 DRAM 讀寫操作，與系統記憶體進行資料通信。在資料傳輸完成後，PCI週邊設備可以產生一個中斷來通知系統。DMA提升了資料傳輸效率，因為這種方式在搬移資料時不需要CPU的參與，那麼對於CPU來說，只需要一個匯流排週期的開銷，將起始地址和總資料量寫入DMA Engine，即可完成高效的資料塊搬移（move a block of data）。

##### 1.4.1.3   Peer-to-Peer(点对点)

如果一個裝置能夠作為匯流排主裝置，那麼它就提供了一個有趣的作用。一個PCI匯流排主設備可以發起針對其他PCI裝置的數據傳輸，而對於PCI匯流排自身來說這整個事務都是在本地進行的，並未引入任何其他系統資源。因為這個事務是在匯流排上的兩個裝置之間進行的，且這兩個裝置被認為是匯流排中兩個對等的節點，因此這個事務被稱作一個“點對點”的事務。顯然，這種事務非常高效，因為系統中其餘的部分仍然可以自由地完成其他的任務。然而，在實際場景中點對點事務很少被使用，這是因為發起者(Initiator)和目標(Target)通常不會使用相同的數據格式，除非二者都是由一個供應商製造的。因此，數據一般必須要首先發送到記憶體，在那裡由CPU在數據傳輸到目標之前，對其進行格式轉換，而這就阻礙並破壞了點對點傳輸的設計目標。

#### 1.4.2     PCI总线仲裁

由圖 1‑2 可知，當今的PCI裝置基本都能作為匯流排主裝置（Bus Master device），所以它們都可以進行DMA與對等傳輸的數據傳輸。在像PCI這種共享匯流排的體系結構中，各裝置需要輪流占用匯流排，因此當一個裝置想要發起事務時必須首先向匯流排仲裁器請求匯流排所有權（ownership）。仲裁器將查看當前所有的請求，並使用一些特定的仲裁實現演算法來決定哪個主設備可以下一個占用匯流排。PCI協議規範並沒有描述這個仲裁演算法，但是有聲明這個仲裁必須是“公平”的，不得在訪問中差別對待任何一個裝置。

仲裁器可以在上一個占用匯流排的主設備還正在進行數據傳輸時就決定出下一個占用匯流排的裝置，這樣匯流排上就不需要引入額外的時延來對下一個匯流排所有者進行排序。因此，匯流排仲裁器的仲裁作用發揮在“幕後”，被稱為“隱藏”的匯流排仲裁，這是一種對早期匯流排協議的改進。

#### 1.4.3 PCI 效能低落部分 (PCI Inefficiencies)
##### 1.4.3.1 PCI 重試協定 (PCI Retry Protocol)

當一個PCI主設備（Master）發起一個事務，用於訪問一個目標裝置（Target），而此時目標裝置並未處於準備就緒狀態（Ready），那麼目標裝置就會給出一個事務重試的訊號，這種場景的示意圖如圖 1‑7。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image016.jpg)

圖 1‑7 PCI 事務重試機制

考慮接下來給出的例子：北橋發起一個讀取記憶體的事務，希望從以太網設備中讀取數據。這個以太網設備（Target）響應這個事務，請求並參與到匯流排週期中來。然而，這個以太網設備Target此刻並沒有立即將數據返回給北橋（Master）。這個以太網設備此時有兩個辦法來推遲這次數據傳輸。第一個辦法就是在數據傳輸中插入等待態（wait-state）。如果過程中僅需插入少量的等待態，那麼數據的傳輸還能算是比較有效率。但是如果Target設備需要延遲更多的時間（從事務被發起後延遲16個時鐘週期以上），那麼就需要用第二種辦法了，第二種辦法就是Target發出一個STOP#訊號來表示事務重試（retry）。Retry操作是通知Master在數據沒有傳輸前就提前結束匯流排週期。這樣做可以防止匯流排長時間處於等待狀態而降低了匯流排效率。當Master接收到Target發來的Retry請求，Master至少等待2個時鐘週期，然後必須重新向匯流排發起仲裁請求，當再次獲得匯流排的使用權之後重新發起相同的匯流排週期。在當前匯流排Master正在處理Retry的這段時間中，仲裁器可以將匯流排使用權授予其他的Master，以便於PCI匯流排能被更有效率的利用起來。當此前執行Retry的Master再次占用匯流排並重新啟動與此前相同的匯流排週期時，Target可能也已經準備好了需要傳輸的數據，並參與到匯流排週期中進行數據傳輸。若Target仍然未準備好，那麼它將會再次發起Retry，按照這樣的流程循環下去直到Master成功完成了數據傳輸。

##### 1.4.3.2 PCI 中斷連線協定 (PCI Disconnect Protocol)

當一個PCI主設備（Master）發起一個事務來訪問一個目標裝置（Target），並且如果這個目標裝置可以傳輸至少一個雙字（doubleword，簡稱dw）的數據，但是它無法完成整個完整的全數據量的傳輸，那麼它將會在它無法繼續進行傳輸時斷開與事務操作的連接。這種場景的示意圖如圖 1‑8 所示。

考慮接下來給出的例子：北橋發起一個突發讀取記憶體事務（burst memory read），希望從以太網設備中讀取數據。以太網目標設備（Target）響應了請求並參與到這個匯流排週期中來，傳輸了部分數據，但是隨後不久把已有的所有數據都發送光了，卻依然沒有達到主設備需要的數據總量。以太網設備目標此時有兩個選擇來延遲數據的傳輸。第一個選擇是在數據傳輸階段插入等待態，然後自身也同時在等待收到新增的數據。如果過程中僅需插入少量的等待態，那麼數據的傳輸還能算是比較有效率。但是如果目標設備需要延遲更多的時間（PCI協議規範中允許在數據傳輸中途最多有8個時鐘週期的等待態，這裡區別於上一節Retry中的16個週期，那是因為那時傳輸還沒開始，而這8個週期針對的是傳輸已經開始了一段時間的傳輸中途等待），目標必須發出斷開連接的訊號。要斷開連接，目標需要在匯流排週期運行中將STOP#置為有效，這樣就能告知主設備提前結束匯流排週期。Disconnect與Retry的一個區別就在於，Disconnect有數據已經被傳輸，而Retry則是數據傳輸根本就沒開始。Disconnect這種操作也讓匯流排避免長時間處於等待態。主設備至少等待2個時鐘週期，然後才能再次向匯流排發起仲裁請求，當再次獲得匯流排的使用權之後就可以再次訪問剛才斷開連接的設備地址，繼續完成此前斷開未完成的匯流排週期。在當前匯流排主設備正在經歷Disconnect的這段時間中，仲裁器可以將匯流排使用權授予其他的主設備，以便於PCI匯流排能被更有效率的利用起來。當此前經歷Disconnect的主設備再次占用匯流排並準備繼續此前未完成的匯流排週期時，目標可能也已經準備好了需要繼續傳輸的數據，並參與到匯流排週期中繼續完成數據傳輸。否則，若目標仍然未準備好，那麼它將會再次發起Retry或者Disconnect，然後按照這樣的流程循環下去直到主設備成功完成了所有數據的傳輸。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image018.jpg)

图 1‑8 PCI事务断开连接机制

#### 1.4.4     PCI中断处理(PCI Interrupt Handling)

PCI裝置使用4個邊帶信號（sideband）作為中斷信號，分別為INTA#、INTB#、INTC#、INTD#，並從中選取一個來向系統發送中斷請求，即使用4個中斷信號中的1個來發送中斷請求。當其中一個中斷引腳被置為有效時，單CPU系統的中斷控制器將會對中斷作出響應，相應的方式為將INTR（interrupt request）信號置為有效，將中斷請求發送給CPU。後來出現的多CPU系統不再適用這種單信號線輸入作為中斷的方式，因此進行了改進，將中斷改為了APIC（Advanced Programmable Interrupt Controller）模型，在這種模型中中斷控制器將會向多CPU發送報文（message）而不是向其中一個CPU發送INTR信號。不過無論中斷傳輸模型是什麼，接收到中斷的CPU都必須確認中斷來源，然後為中斷提供服務。傳統的模型需要好幾個匯流排週期來完成確認中斷和服務中斷的操作，效率不是很高。APIC模型會比傳統模型好一些但是也依然存在改進的空間。

#### 1.4.5     PCI错误处理(PCI Error Handling)

PCI裝置可以選擇在事務進行期間檢測並報告接收到的地址或數據訊號中的奇偶校驗錯誤。在事務進行期間，PCI對匯流排上的大部分訊號進行奇偶校驗，並通過PAR訊號來表示計算出的偶校驗位結果。如果傳輸的數據或地址信息中邏輯電平1的位元數量為奇數，則PAR訊號將被置為1，以此使含有“電平1”的位元數量變為偶數。目標裝置在接收到數據或地址時會進行校驗，檢查是否有錯誤。奇偶校驗（在此為偶校驗）只在有奇數個錯誤的訊號時能被檢測出來。如果裝置檢測到數據的奇偶校驗錯誤，它會將PERR#（parity error）訊號置為有效。這可能是一個可恢復的錯誤，例如對於記憶體讀取，只需重新發起相同的事務即可解決問題。然而，PCI本身不包含任何自動或基於硬體的錯誤恢復機制，因此軟體需要完全負責錯誤處理。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image020.jpg)

图 1‑9 PCI错误处理

然而，上述所說的是數據出錯的情況，若地址校驗出錯則情況不同。在圖 1‑9 的例子中，地址信息損壞，這導致一個目標裝置（Target）匹配上了這個錯誤的地址。我們無法得知損壞的地址信息變成了什麼，也無法得知匯流排上哪個裝置匹配上了這個錯誤的地址，所以對於這種情況就不存在能夠簡單進行錯誤恢復的方法。因此，這種類型的錯誤將會導致SERR#（系統錯誤）被置為有效，之後系統通常會調用錯誤處理程序。在老式機器中，為了預防引起更進一步的錯誤，將會強行讓系統停止工作，從而導致出現“藍屏死機”。

#### 1.4.6     PCI地址空间映射(PCI Address Map)

PCI體系結構支持3種地址空間，如圖 1‑10所示，包括：記憶體（Memory）、I/O（輸入/輸出）及配置地址空間（Configuration Address Space）。x86處理器可以直接訪問記憶體和I/O空間。一個PCI裝置映射到處理器記憶體地址空間時，可以支持32位或64位定址。在I/O地址空間中，PCI裝置可以支持32位定址，但因為x86 CPU僅使用16位的I/O地址空間，許多平台因此將I/O空間限制在64KB（對應16 bit）。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image022.jpg)

图 1‑10地址空间映射

PCI還引進了第三種地址空間，稱為配置空間，CPU只能對其進行間接訪問，而非直接訪問。PCI裝置中的每個功能（Function）都包含專為配置空間所準備的內部寄存器，這些寄存器對於軟體來說是可見的，軟體可以通過一個標準化的方式來控制它們的地址與資源，這為PC提供了一個真正的即插即用（plug and play）的環境。每個PCI Function最多可以有256 Bytes的配置地址空間。考慮到PCI最多可支持單個裝置含有8個Function、每條匯流排含有32個裝置、單個系統包含256條匯流排，那麼可以得出一個系統的配置空間總量為：

256B/Function *8Function/device * 32devices/bus *256buses/system =16MB，

即一個系統的配置空間總大小為16MB。

由於x86 CPU無法直接訪問配置空間，因此它必須通過IO暫存器進行索引。（在PCI Express中引入了一種新方法來訪問配置空間，即通過將配置空間映射入記憶體地址空間來完成。）在傳統模型中，如圖 1‑10 所示，使用了被稱為配置地址埠（位址CF8h-CFBh）的IO埠口，以及被稱為配置數據埠（位址CFCh-CFFh）的IO埠口。關於通過這種方法以及通過記憶體映射方法訪問配置空間的細節，將在下一節進行解釋。

#### 1.4.7     PCI配置周期的生成(PCI Configuration Cycle Generation)

由于IO地址空间的大小是有限的，传统模型的设计上对地址十分保守。在IO空间中常见的做法是令一个寄存器来指向一个内部位置，然后用另一个寄存器来进行数据的读取或写入。PCI的配置过程包含如下两步。

l 第一步：CPU产生一个IO写，写入的位置为北桥中IO地址为CF8h的地址端口（Address Port），这样就给出了需要被配置的寄存器的地址，即“用一个寄存器来指向一个内部位置”。如图 1‑11所示，这个地址主要由三部分组成，通过这三部分就可以定位一个PCI Function在拓扑结构中的位置，它们为：在256条总线中我们想访问哪一条总线、在该总线上的32个设备中访问哪一个、在该设备的8个Function中访问哪一个。除了这些以外，唯一还需要提供的信息是要确认访问这个Function的64dw（256Bytes）中的哪个dw。

l 第二步：CPU产生一个IO读或者IO写，操作的位置为北桥中的地址为CFCh的数据端口（Data Port），即“用另一个寄存器来进行数据的读取或写入”。在此基础上，北桥向PCI总线发起一个配置读事务（configuration read）或配置写事务（configuration write），事务要操作的地址即为步骤一中地址端口中所指定的地址。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image024.jpg)

图 1‑11配置地址寄存器

#### 1.4.8     PCI Function配置寄存器空间(PCI Function Cfg Reg Space)

每个PCI Function可以包含最多256Bytes的配置空间。这个配置空间起始的64Bytes包含一个被称为Header（配置空间头）的结构，剩余的192Bytes用来支持一些其他可选功能。系统配置首先由Boot ROM固件来执行，在操作系统被加载完成后，它将重新对系统进行配置，重新进行资源分配。这也就是说系统配置的过程可能会被执行两次。

根据Header的类型，PCI Function被分为两个基本的类别。第一种Header称为Type 1 Header（类型1），它的结构如图 1‑12，它用于标识这个Function是一个Bridge，Bridge将会在拓扑结构上创建另一条总线。而Type 0 Header（类型0）就是用来指示这个Function**不是**一个Bridge（如图 1‑13）。关于Header类型的信息包含在dword3的字节2的同名字段中（Class Code字段），当软件在系统中发现某个Function时，第一件事就是要检查其Header的这个字段（软件发现系统中Function的过程称为枚举enumeration）。

关于配置寄存器空间以及枚举过程的更为详细的讲解将会稍后再进行。在这里我们只是希望你先熟悉一下各个部分是如何相互配合工作的。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image026.jpg)

图 1‑12 PCI配置Header Type 1（Bridge）

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image028.jpg)

图 1‑13 PCI配置Header Type 0（非Bridge）



 

#### 1.4.9     更高带宽的PCI(Higher-bandwidth PCI)

为了支持更高的带宽，PCI协议规范更新成了支持位宽更宽（64bit），时钟速率更快（66MHz）的版本，使其可以达到533MB/s的速率。图 1‑14展示了一个使用66MHz 64bit PCI总线的系统。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image030.jpg)

图 1‑14 基于66MHz PCI总线的平台

##### 1.4.9.1   66MHz PCI总线的限制

66MHz总线的吞吐量相较于33MHz已经翻倍，但是其存在一定的问题，图 1‑14显示了它的一个主要缺点：66MHz总线与33MHz总线使用相同的反射波开关模型，使得留给在传输线上信号传输的时间减半，这将会大大的降低总线的负载能力。最终造成的结果是，一条总线上只能有一个插入板卡。增加更多的设备意味着需要增加更多的PCI Bridge来产生更多的总线，这将会增加成本以及对PCB板材的要求。同时，64bit PCI总线相较于32bit增加了引脚数，这也会增加系统成本且降低可靠性。将上述结合起来，就可以很容易看出来为什么这些因素限制了64bit或者66MHz版本的PCI总线的广泛使用。

##### 1.4.9.2   并行PCI总线模型在66MHz以上时出现的信号时序问题

鉴于PCI总线上的实际负载以及信号渡越时间（signal flight times），PCI总线的时钟频率无法在66MHz上继续增加了。对于66MHz时钟来说，其时钟周期为15ns。分配给接收器的建立时间(Setup time)为3ns。因为PCI使用“非寄存输入（non-registered input）”信号模型，想要将其3ns的建立时间继续减小是不现实的。剩余的12ns的时序预算（timing budget）分配给了发送器的输出延迟以及信号传输时间。如果在66MHz的基础上进一步提高频率，那么总线上传输的信号将会因为无法及时到达接收端，无法在接收端被正确采样，从而导致传输失败。

在下一节将会介绍PCI-X总线，它将所有的输入信号都先用触发器来寄存一下，然后再去使用。这样做可以将信号的建立时间降低到1ns以下。在建立时间上的优化使得PCI-X总线可以跑到一个更高的频率，例如100MHz甚至133MHz。下一节中我们将会对PCI-X总线体系结构进行简明的介绍。

### 1.5 PCI-X简介

PCI-X对PCI的软件和硬件都能做到向后兼容，同时PCI-X还能提供更好的性能和更高的效率。它和PCI所使用的连接器也是相同的，因此PCI-X与PCI的设备可以插入相互的插槽。除此之外，它们二者还使用相同的配置模型，因此在PCI系统中能使用的设备、操作系统、以及应用，在PCI-X系统中仍然可以使用。

为了在不改变PCI信号传输模型的基础上达到更高的速率，PCI-X使用了几个技巧来改善总线时序。首先，他们实现了PLL（锁相环）时钟发生器，利用它在内部提供相移时钟。这使得输出信号在相位上前移，而输入再在相位上延后一点进行采样，从而改善总线上的时序。同时，PCI-X的输入信号都在Target设备的输入引脚被寄存（锁存），这样就使得建立时间更小。通过这些方法节省出来的时间可以有效增加信号在总线上传输的可用时间，并使得总线可以进一步提高时钟频率。

#### 1.5.1     PCI-X系统示例(PCI-X System Example)

如图 1‑15所示，这是一个基于Intel 7500服务器芯片组的系统平台。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image032.jpg)

图 1‑15基于66MHz/33MHz PCI-X总线的平台

MCH（Memory Controller Hub）芯片提供了3个额外的高性能的Hub-Link 2.0端口，它们各与一个PCI-X 2 Bridge（P64H2）相连接。每个Bridge支持两条PCI-X总线，总线最高时钟频率可以达到133MHz。Hub Link 2.0可以支撑PCI-X更高带宽的数据流。需要注意的是，在PCI-X上我们依然存在与当初改进66MHz PCI时遇到的一样的负载方面的问题，这使得如果我们要支持更多的设备那么就需要使用Bridge来生成更多的总线，并且这将会是一个相对成本昂贵的解决方案。不过，现在的带宽确实提高了不少。

#### 1.5.2     PCI-X事务(PCI-X Transactions)

如图 1‑16所示，这是一个PCI-X总线上Memory突发读取（burst memory read）事务。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image034.jpg)

图 1‑16 PCI-X Memory突发读取的总线时序周期示例

需要注意的是，PCI-X并不允许在第一个数据阶段（first data phase）后插入等待态。之所以这样做是因为PCI-X中会在事务的属性阶段（Attribute Phase），将需要传输的数据总量告诉Target设备。因此与PCI不同，Target是知道自己需要传输多少数据的。此外，多数PCI-X总线时序周期是连续的，因为使用的是突发模式，并且数据通常以128Bytes作为一个数据块（block）来进行传输。这些特性使得总线利用率提高，同时也提高了设备buffer管理的效率。

#### 1.5.3     PCI-X特性(PCI-X Features)

##### 1.5.3.1   拆分事务模型（Split-Transaction Model）

在传统的PCI读事务中，总线Master向总线上某个设备发起读取。如前面的内容所述，若Target设备未准备好，无法完成事务，那么它既可以选择在获取数据的同时让总线保持等待态，也可以发起Retry来推迟事务。

PCI-X则不同，它使用拆分事务的方法来处理这些情况，如图 1‑17所示。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image036.jpg)

图 1‑17 PCI-X 拆分事务处理协议

为了方便描述追踪每个设备正在做什么，我们现在将例子中发起读取操作的一方称为Requester（请求方），将完成读取请求提供数据的一方称为Completer（完成方）。如果Completer无法马上对请求做出相应的服务，它将把这个事务的相关信息存储起来（地址、事务类型、总数据量、Requester ID），并发出拆分响应信号。这就告诉Requester可以将这个事务先放置在队列中，并结束当前的总线时序周期，释放总线使之回到空闲状态。这样，在Completer等待所请求的数据这段时间里，总线上可以执行其他的事务。Requester在这段时间里也可以自由的做其他事情，比如发起另一个请求，甚至是向此前的那个Completer发起请求都可以。一旦Completer收集到了所请求的数据，它将会申请总线占用仲裁，当获取到总线的使用权后，它将发起一个拆分完成（Split Completion）来返回此前Requester所请求的数据。Requester将会响应并参与拆分完成这个事务的总线时序周期，在这个过程中接收来自Completer的数据。对于系统来说，拆分完成事务其实与写事务非常相似。这种拆分事务模型（Split Transaction Model）的可行性在于，在请求发起时就通过属性阶段（Attribute Phase）指出了总共需要传输多少数据，并且也告诉了Completer是谁发起了这个请求（通过提供Requester自己的Bus:Device:Function号码），这使得Completer在发起拆分完成事务时能够找到正确的目标。

对于上述的整个数据传输过程来说，需要通过两个总线事务来完成，但是读请求和拆分完成这两个事务之间的这段时间里，总线是可以执行其他任务的。Requester不需要重复的轮询设备来检查数据是否已经准备好。Completer只需要简单的申请总线占用仲裁，然后在能使用总线时将被请求的数据返回给Requester即可。就总线利用率而言，这样的操作流程使得事务模型更加高效。

到目前为止，对PCI-X所做的这些协议增强改进使得PCI-X的传输效率提高至约85%，而使用标准PCI协议则为50%-60%。

##### 1.5.3.2   MSI消息式中断（Message Signaled Interrupts）

PCI-X设备需要支持MSI中断（Message Signaled Interrupts），在传统中断体系结构中经常见到多个设备需要共享中断，开发这种功能是为了减少或者消除这种需要。想要产生一个MSI中断请求，设备需要发起一个memory写事务，其操作地址为一段预先定义好的地址区域，在这个地址区域内的一个写入操作就会被视为是一个中断，这个信息将会被传送给一个或多个CPU，写入的数据则是发起中断的设备的中断向量，这个中断向量在系统中是唯一的，仅指向这一个设备。对于CPU来说，拥有了中断号之后就可以迅速的跳转到对应设备的中断服务程序，这样就避免了还需要花费额外的开销来查找是那个设备发起的中断。此外，这样的中断方式就不需要额外的中断引脚了。

##### 1.5.3.3   事务属性（Transaction Attributes）

最后，我们来介绍一下PCI-X在每个事务开始时新加入的一个阶段，称之为属性阶段（如图 1‑16所示）。在段时间中，Requester会将所发起事务的一些信息传递给Completer，信息包括请求的总数据量大小、Requester是谁（Bus:Device:Function 号码），这些信息可以有效的让总线上的事务执行提升效率。除了这些以外，还新引入了2bit的信号来描述所发起的事务：“No Snoop（无窥探）”位与“Relaxed Ordering（宽松排序）”位。

l **No Snoop**（NS）：一般来说，当一个事务要把数据移入或者移出Memory时，CPU内部的Cache需要检查被操作的Memory区域中是否存在已经被拷贝到Cache中的部分。若存在，那么Cache需要在事务访问Memory之前就把数据写回Memory，或是把Cache内的数据按失效处理。当然，这个窥探Memory内容有无出现在cache中的过程将会消耗一定的时间，并且会增加这个请求的延迟。在有些情况下，软件是知道某个请求的Memory位置永远不会出现在Cache中（这可能是因为这个位置被系统定义为不可缓存的），因此对于这些位置是不需要进行窥探的，应该跳过这一步骤。No Snoop位正是基于这种原因而被引入进来。

l **Relaxed Ordering**（RO）：通常情况下，当事务通过Bridge的buffer时，事务间需要保持当初被放置到总线上时的顺序。这被称为强排序模型（Strongly ordered model），PCI与PCI-X一般都会遵循这种规则，除了一些个别情况。这是因为强排序模型可以解决有相互联系的事务之间的依赖问题，例如对同一个位置先进行写入再进行读取，按照强排序模型就可以使得读取操作读取到写入后的正确数据，而不是写入前的旧数据。然而实际上并不是所有的事务都存在依赖关系。如果有些事务不存在依赖关系，那么依然强制它们保持原来的顺序将会造成性能损失，这就是新添加这一属性比特位想解决的问题。如果Requester知道某个特定的事务是与此前其他事务不相关联的，那么就可以将这个事务的这一位置为有效，这样就能告诉Bridge可以在队列中向前调度该事务，提前执行，以此带来更好的性能。

#### 1.5.4     更高带宽的PCI-X(Higher Bandwidth PCI-X)

##### 1.5.4.1   PCI与PCI-X 1.0并行总线模型中由于公共时钟方法所带来的问题

当尝试将PCI这样的总线升级到更高的速率时，一个问题变得越来越明显，那就是并行总线设计存在一些固有的先天局限。图 1‑18可以有助于理解这个问题。这些设计通常使用公共时钟（common clock）或者是分布式时钟（distributed clock），其中，发送方在公共时钟的某一个时钟沿将数据输出，然后接收方在公共时钟的下一个时钟沿将数据锁存，也就是说用于传输的时间预算长度就是一个时钟周期。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image038.jpg)

图 1‑18并行设计的固有问题

需要注意的第一个问题是信号歪斜（signal skew）。当数据的多个bit在同一时刻被发出，他们所经历的延时会存在轻微的差别，这使得他们到达接收方的时刻也会存在轻微的差别。如果某些原因造成这种差别过大，那么就会出现图中所示的信号采样错误的问题。第二个问题是多个设备间的时钟歪斜问题。公共时钟到达各个设备的时间点并不是十分精确一致的，这也会大大的压缩了用于传输信号的时间预算长度。最后，第三个问题与一个信号从发送方传输到接收方所需要的时间有关，我们称这个时间为渡越时间（flight time）。时钟周期或是传输时间预算必须要大于信号渡越时间。为了确保满足这样的条件，PCB硬件板级设计需要让信号走线尽可能短，以此来让信号传输时延小于时钟周期。在许多电路板设计中，这种短信号走线的设计并不现实。

尽管存在这些自身局限，但是为了更进一步提升性能，还是有几项技术可以使用的。首先，可以对现有的协议进行简化而提高效率。第二，可以将总线模型更改为源同步时钟模型（source synchronous clocking model），在这种时钟模型中，总线信号和时钟（strobe选通脉冲）被驱动后将经历相同的传输延迟到达接收端（这里可以对比一下common clock与其的区别）。这种方法被PCI-X 2.0所采用。

##### 1.5.4.2   PCI-X 2.0源同步模型（PCI-X 2.0 Source-Synchronous Model）

PCI-X2.0更进一步的提高了PCI-X的带宽。如此前升级时一样，PCI-X 2.0依然保持了对PCI的软件与硬件的向后兼容性。为了达到更高的速率，总线使用了源同步传输模型，来支持DDR（双倍数据速率）或是QDR（四倍数据速率）。

“源同步”这个术语的意思是，设备在传输数据的同时，还提供了额外一个与数据信号基本传输路径相同的信号。如图 1‑19所示，在PCI-X 2.0中，那个“额外”的信号被称为“strobe（脉冲选通）”，接收方使用它来锁存发来的数据。发送方可以分配data与strobe信号之间的时序关系，只要data与strobe信号的传输路径长度相近且其他会影响传输延迟的条件也相近，那么当信号到达接收方时，这种信号间的时序关系也将不会发生变化。这种特点可以用于支持更高速率的传输，这是因为在源同步时钟模型中，接收方采样所使用的strobe（类似于原来的时钟）也是数据的来源方发送的，这样就避免了公共时钟到达各设备的延时不同而造成的时钟歪斜问题，因为如上所述此时的data与strobe之间的时序关系是基本相对不变的，这样就将时钟歪斜的这段时间单独剔除了出去，不再占用原来的传输时间预算。除此之外，因为存在了strobe信号来随路指示接收方何时锁存采样数据，所以信号渡越时间不再是个问题，即使走线较长也依然能由伴随data的strobe信号来让接收方正确的采样数据，而不必纠结在下一个“时钟上升沿”必须要进行采样，现在strobe何时指示则在何时采样。

![img](img/1%20%E8%83%8C%E6%99%AF/clip_image040.jpg)

图 1‑19源同步时钟模型

需要再次强调的是，这种非常高速的信号时序使得共享总线模型无法被使用，它只能被设计为点对点的传输形式。因此，想要增加更多的设备就需要更多的Bridge来产生更多的总线。为了达到这样的使用方法，可以设计一种设备，它拥有3个PCI-X 2.0接口，其内部还有一个Bridge结构以此来让他们三者进行相互通信。不过，这样的设备将会具有很高的引脚数量，而且成本也会更高，这使得PCI-X 2.0被困在了高端市场而无法大面积普及。

由于协议制定者认识到了PCI-X 2.0的昂贵解决方案仅能吸引更多的高端开发者而不是一般开发者，因此PCI-X 2.0提供了更符合高端设计的技术标准，例如支持ECC的生成与校验。PCI-X的ECC比PCI中使用的奇偶校验要更为复杂，鲁棒性（robust）也要高得多，它可以动态的自动纠正单bit错误，以及对多bit错误进行可靠的检测。这种改进后的错误处理方法增加了成本，但是对于高端平台来说，它所能增加的可靠性才是更为看中的，因此即使增加了成本这也是一个合理的选择。

尽管PCI-X 2.0将带宽、效率以及可靠性都提升了，但是并行总线的终究还是走到了它的终点，需要一种新的模型来满足人们对于更高带宽且更低成本的不断的需求。最终被选中的新型总线模型使用的是串行接口，从物理层面来看它与PCI是完全不同的总线，但是它在软件层面保留了对PCI的向后兼容性。

这个新模型，就是我们所知道的PCI Express（PCIe）。

------

原文：  Mindshare

译者：  Michael ZZY

校对：  LJGibbs

欢迎参与 《Mindshare PCI Express Technology 3.0 一书的中文翻译计划》

https://gitee.com/ljgibbs/chinese-translation-of-pci-express-technology

